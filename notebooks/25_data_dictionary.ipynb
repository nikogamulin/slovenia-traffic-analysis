{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 25. Data Dictionary\n",
    "\n",
    "**Story 1.15**: Data Dictionary\n",
    "\n",
    "## Objectives\n",
    "- Document all features and transformations\n",
    "- Create markdown documentation\n",
    "- Generate feature metadata\n",
    "- Build comprehensive data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T13:40:47.671334Z",
     "iopub.status.busy": "2025-09-06T13:40:47.670635Z",
     "iopub.status.idle": "2025-09-06T13:40:47.857724Z",
     "shell.execute_reply": "2025-09-06T13:40:47.857341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional, Union\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, asdict\n",
    "import re\n",
    "\n",
    "print('Libraries loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Metadata Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T13:40:47.871678Z",
     "iopub.status.busy": "2025-09-06T13:40:47.871528Z",
     "iopub.status.idle": "2025-09-06T13:40:47.876036Z",
     "shell.execute_reply": "2025-09-06T13:40:47.875864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dictionary classes defined\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class FeatureMetadata:\n",
    "    \"\"\"Metadata structure for features.\"\"\"\n",
    "    name: str\n",
    "    display_name: str\n",
    "    description: str\n",
    "    data_type: str\n",
    "    category: str\n",
    "    unit: Optional[str] = None\n",
    "    valid_range: Optional[List[Union[int, float]]] = None\n",
    "    example_values: Optional[List[Any]] = None\n",
    "    missing_value_handling: Optional[str] = None\n",
    "    transformation: Optional[str] = None\n",
    "    source: Optional[str] = None\n",
    "    business_meaning: Optional[str] = None\n",
    "    related_features: Optional[List[str]] = None\n",
    "    quality_checks: Optional[List[str]] = None\n",
    "    importance_score: Optional[float] = None\n",
    "    created_date: Optional[str] = None\n",
    "    last_updated: Optional[str] = None\n",
    "\n",
    "class DataDictionary:\n",
    "    \"\"\"Comprehensive data dictionary for traffic features.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.features = {}\n",
    "        self.categories = {}\n",
    "        self.transformations = {}\n",
    "        self.created_date = datetime.now().isoformat()\n",
    "        \n",
    "    def add_feature(self, feature: FeatureMetadata):\n",
    "        \"\"\"Add a feature to the dictionary.\"\"\"\n",
    "        self.features[feature.name] = feature\n",
    "        \n",
    "        # Update categories\n",
    "        if feature.category not in self.categories:\n",
    "            self.categories[feature.category] = []\n",
    "        self.categories[feature.category].append(feature.name)\n",
    "    \n",
    "    def get_feature(self, name: str) -> Optional[FeatureMetadata]:\n",
    "        \"\"\"Get feature metadata by name.\"\"\"\n",
    "        return self.features.get(name)\n",
    "    \n",
    "    def get_features_by_category(self, category: str) -> List[FeatureMetadata]:\n",
    "        \"\"\"Get all features in a category.\"\"\"\n",
    "        feature_names = self.categories.get(category, [])\n",
    "        return [self.features[name] for name in feature_names]\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary.\"\"\"\n",
    "        return {\n",
    "            'created_date': self.created_date,\n",
    "            'categories': self.categories,\n",
    "            'total_features': len(self.features),\n",
    "            'features': {name: asdict(feature) for name, feature in self.features.items()}\n",
    "        }\n",
    "    \n",
    "    def save_json(self, filepath: str):\n",
    "        \"\"\"Save to JSON file.\"\"\"\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(self.to_dict(), f, indent=2, default=str)\n",
    "    \n",
    "    def save_yaml(self, filepath: str):\n",
    "        \"\"\"Save to YAML file.\"\"\"\n",
    "        with open(filepath, 'w') as f:\n",
    "            yaml.dump(self.to_dict(), f, default_flow_style=False, indent=2)\n",
    "\n",
    "print('Data dictionary classes defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Sample Data with Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T13:40:47.877112Z",
     "iopub.status.busy": "2025-09-06T13:40:47.877029Z",
     "iopub.status.idle": "2025-09-06T13:40:47.896312Z",
     "shell.execute_reply": "2025-09-06T13:40:47.896134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sample data with 2000 records and 44 features\n",
      "\n",
      "Feature categories:\n",
      "  Temporal: 15 features\n",
      "  Weather: 7 features\n",
      "  Traffic: 12 features\n",
      "  Boolean: 14 features\n",
      "  Station: 4 features\n",
      "  Derived: 5 features\n",
      "\n",
      "Sample data:\n",
      "            timestamp station_id  vehicle_count  avg_speed  occupancy  \\\n",
      "0 2024-01-01 00:00:00  A3_KM_203      99.000000  66.072860  25.232779   \n",
      "1 2024-01-01 01:00:00  A1_KM_125     118.176381  78.163478  54.125647   \n",
      "2 2024-01-01 02:00:00  A3_KM_203      86.000000  80.462070  35.251584   \n",
      "3 2024-01-01 03:00:00  A3_KM_203     109.142136  78.074770   4.208597   \n",
      "4 2024-01-01 04:00:00  A1_KM_125     117.320508  71.136690  10.727314   \n",
      "\n",
      "   temperature  precipitation   visibility  wind_speed    humidity  ...  \\\n",
      "0    26.064651       2.765788  9345.361848    2.245537   73.356962  ...   \n",
      "1    20.265854       0.536013  2219.982272   18.826244  100.000000  ...   \n",
      "2    26.030155       4.213665   590.241866   14.677149   98.642469  ...   \n",
      "3    12.084505       1.516077  4934.053093    0.081393   90.597137  ...   \n",
      "4    24.242460       1.850155  6231.336888   16.284168   61.717551  ...   \n",
      "\n",
      "   congestion_score  flow_efficiency  station_A3KM203  station_A1KM125  \\\n",
      "0         38.189325         6.541213                1                0   \n",
      "1         69.246724         9.237077                0                1   \n",
      "2         43.811430         6.919738                1                0   \n",
      "3          5.390470         8.521247                1                0   \n",
      "4         15.079861         8.345793                0                1   \n",
      "\n",
      "   station_A2KM89  vehicle_count_lag1  avg_speed_lag1  occupancy_lag1  \\\n",
      "0               0                 NaN             NaN             NaN   \n",
      "1               0           99.000000       66.072860       25.232779   \n",
      "2               0          118.176381       78.163478       54.125647   \n",
      "3               0           86.000000       80.462070       35.251584   \n",
      "4               0          109.142136       78.074770        4.208597   \n",
      "\n",
      "   vehicle_count_ma3  avg_speed_ma3  \n",
      "0                NaN            NaN  \n",
      "1                NaN            NaN  \n",
      "2         101.058794      74.899469  \n",
      "3         104.439506      78.900106  \n",
      "4         104.154215      76.557843  \n",
      "\n",
      "[5 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "# Generate comprehensive sample data\n",
    "np.random.seed(42)\n",
    "n_samples = 2000\n",
    "\n",
    "# Create datetime range\n",
    "dates = pd.date_range('2024-01-01', periods=n_samples, freq='H')\n",
    "\n",
    "# Generate base traffic data\n",
    "sample_data = pd.DataFrame({\n",
    "    # Raw sensor data\n",
    "    'timestamp': dates,\n",
    "    'station_id': np.random.choice(['A1_KM_125', 'A2_KM_89', 'A3_KM_203'], n_samples),\n",
    "    'vehicle_count': np.random.poisson(100, n_samples) + 20 * np.sin(2 * np.pi * np.arange(n_samples) / 24),\n",
    "    'avg_speed': np.clip(np.random.normal(80, 15, n_samples), 20, 130),\n",
    "    'occupancy': np.clip(np.random.beta(2, 5, n_samples) * 100, 0, 100),\n",
    "    \n",
    "    # Weather data\n",
    "    'temperature': np.random.normal(15, 10, n_samples),\n",
    "    'precipitation': np.clip(np.random.exponential(2, n_samples), 0, 50),\n",
    "    'visibility': np.clip(np.random.normal(5000, 2000, n_samples), 100, 10000),\n",
    "    'wind_speed': np.clip(np.random.exponential(8, n_samples), 0, 50),\n",
    "    'humidity': np.clip(np.random.normal(70, 20, n_samples), 0, 100),\n",
    "})\n",
    "\n",
    "# Add derived temporal features\n",
    "sample_data['hour'] = sample_data['timestamp'].dt.hour\n",
    "sample_data['day_of_week'] = sample_data['timestamp'].dt.dayofweek\n",
    "sample_data['month'] = sample_data['timestamp'].dt.month\n",
    "sample_data['day_of_year'] = sample_data['timestamp'].dt.dayofyear\n",
    "sample_data['week_of_year'] = sample_data['timestamp'].dt.isocalendar().week\n",
    "\n",
    "# Cyclical encoding\n",
    "sample_data['hour_sin'] = np.sin(2 * np.pi * sample_data['hour'] / 24)\n",
    "sample_data['hour_cos'] = np.cos(2 * np.pi * sample_data['hour'] / 24)\n",
    "sample_data['day_sin'] = np.sin(2 * np.pi * sample_data['day_of_week'] / 7)\n",
    "sample_data['day_cos'] = np.cos(2 * np.pi * sample_data['day_of_week'] / 7)\n",
    "sample_data['month_sin'] = np.sin(2 * np.pi * sample_data['month'] / 12)\n",
    "sample_data['month_cos'] = np.cos(2 * np.pi * sample_data['month'] / 12)\n",
    "\n",
    "# Boolean features\n",
    "sample_data['is_weekend'] = (sample_data['day_of_week'] >= 5).astype(int)\n",
    "sample_data['is_holiday'] = np.random.choice([0, 1], n_samples, p=[0.95, 0.05])\n",
    "sample_data['is_morning_rush'] = ((sample_data['hour'] >= 7) & (sample_data['hour'] < 9)).astype(int)\n",
    "sample_data['is_evening_rush'] = ((sample_data['hour'] >= 16) & (sample_data['hour'] < 18)).astype(int)\n",
    "sample_data['is_rush_hour'] = ((sample_data['is_morning_rush'] == 1) | (sample_data['is_evening_rush'] == 1)).astype(int)\n",
    "\n",
    "# Weather condition flags\n",
    "sample_data['is_rainy'] = (sample_data['precipitation'] > 1.0).astype(int)\n",
    "sample_data['is_foggy'] = (sample_data['visibility'] < 1000).astype(int)\n",
    "sample_data['is_windy'] = (sample_data['wind_speed'] > 15).astype(int)\n",
    "sample_data['is_cold'] = (sample_data['temperature'] < 5).astype(int)\n",
    "sample_data['is_hot'] = (sample_data['temperature'] > 25).astype(int)\n",
    "\n",
    "# Composite weather severity\n",
    "sample_data['weather_severity'] = (\n",
    "    sample_data['is_rainy'] + \n",
    "    sample_data['is_foggy'] + \n",
    "    sample_data['is_windy']\n",
    ")\n",
    "\n",
    "# Traffic-derived features\n",
    "sample_data['traffic_density'] = sample_data['vehicle_count'] / (sample_data['avg_speed'] + 1)\n",
    "sample_data['is_congested'] = (sample_data['occupancy'] / 100 > 0.6).astype(int)\n",
    "sample_data['congestion_score'] = np.clip(sample_data['occupancy'] / sample_data['avg_speed'] * 100, 0, 100)\n",
    "sample_data['flow_efficiency'] = sample_data['avg_speed'] * sample_data['vehicle_count'] / 1000\n",
    "\n",
    "# Station-specific features (one-hot encoding)\n",
    "for station in sample_data['station_id'].unique():\n",
    "    sample_data[f'station_{station.replace(\"_\", \"\")}'] = (sample_data['station_id'] == station).astype(int)\n",
    "\n",
    "# Lag features (previous hour)\n",
    "sample_data['vehicle_count_lag1'] = sample_data['vehicle_count'].shift(1)\n",
    "sample_data['avg_speed_lag1'] = sample_data['avg_speed'].shift(1)\n",
    "sample_data['occupancy_lag1'] = sample_data['occupancy'].shift(1)\n",
    "\n",
    "# Rolling averages\n",
    "sample_data['vehicle_count_ma3'] = sample_data['vehicle_count'].rolling(window=3).mean()\n",
    "sample_data['avg_speed_ma3'] = sample_data['avg_speed'].rolling(window=3).mean()\n",
    "\n",
    "print(f'Generated sample data with {len(sample_data)} records and {len(sample_data.columns)} features')\n",
    "print('\\nFeature categories:')\n",
    "feature_counts = {\n",
    "    'Temporal': len([col for col in sample_data.columns if any(x in col.lower() for x in ['hour', 'day', 'month', 'week', 'sin', 'cos', 'timestamp'])]),\n",
    "    'Weather': len([col for col in sample_data.columns if any(x in col.lower() for x in ['temp', 'precip', 'wind', 'humid', 'visib', 'weather'])]),\n",
    "    'Traffic': len([col for col in sample_data.columns if any(x in col.lower() for x in ['vehicle', 'speed', 'occupancy', 'density', 'flow', 'congestion'])]),\n",
    "    'Boolean': len([col for col in sample_data.columns if sample_data[col].dtype == 'int64' and set(sample_data[col].dropna().unique()).issubset({0, 1})]),\n",
    "    'Station': len([col for col in sample_data.columns if col.startswith('station_')]),\n",
    "    'Derived': len([col for col in sample_data.columns if any(x in col.lower() for x in ['lag', 'ma'])]),\n",
    "}\n",
    "\n",
    "for category, count in feature_counts.items():\n",
    "    print(f'  {category}: {count} features')\n",
    "\n",
    "print('\\nSample data:')\n",
    "print(sample_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Complete Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T13:40:47.897390Z",
     "iopub.status.busy": "2025-09-06T13:40:47.897306Z",
     "iopub.status.idle": "2025-09-06T13:40:47.904989Z",
     "shell.execute_reply": "2025-09-06T13:40:47.904822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 22 feature definitions to data dictionary\n",
      "Categories: ['temporal', 'temporal_cyclical', 'weather', 'traffic_raw', 'traffic_derived', 'temporal_boolean', 'traffic_boolean', 'weather_boolean', 'station', 'temporal_lag', 'temporal_smoothed']\n",
      "Total features in dictionary: 22\n"
     ]
    }
   ],
   "source": [
    "# Initialize data dictionary\n",
    "data_dict = DataDictionary()\n",
    "\n",
    "# Define feature metadata for each feature\n",
    "feature_definitions = [\n",
    "    # Temporal Features\n",
    "    FeatureMetadata(\n",
    "        name='timestamp',\n",
    "        display_name='Timestamp',\n",
    "        description='Date and time of the measurement',\n",
    "        data_type='datetime64[ns]',\n",
    "        category='temporal',\n",
    "        unit='datetime',\n",
    "        source='traffic_sensors',\n",
    "        business_meaning='When the traffic measurement was taken',\n",
    "        quality_checks=['not_null', 'chronological_order'],\n",
    "        importance_score=1.0\n",
    "    ),\n",
    "    FeatureMetadata(\n",
    "        name='hour',\n",
    "        display_name='Hour of Day',\n",
    "        description='Hour component of the timestamp (0-23)',\n",
    "        data_type='int64',\n",
    "        category='temporal',\n",
    "        unit='hour',\n",
    "        valid_range=[0, 23],\n",
    "        example_values=[0, 6, 12, 18, 23],\n",
    "        transformation='extract_hour_from_timestamp',\n",
    "        source='derived_from_timestamp',\n",
    "        business_meaning='Used to identify daily traffic patterns and peak hours',\n",
    "        importance_score=0.9\n",
    "    ),\n",
    "    FeatureMetadata(\n",
    "        name='day_of_week',\n",
    "        display_name='Day of Week',\n",
    "        description='Day of the week (0=Monday, 6=Sunday)',\n",
    "        data_type='int64',\n",
    "        category='temporal',\n",
    "        unit='day',\n",
    "        valid_range=[0, 6],\n",
    "        example_values=[0, 1, 2, 3, 4, 5, 6],\n",
    "        transformation='extract_dayofweek_from_timestamp',\n",
    "        source='derived_from_timestamp',\n",
    "        business_meaning='Distinguishes weekday vs weekend traffic patterns',\n",
    "        related_features=['is_weekend'],\n",
    "        importance_score=0.8\n",
    "    ),\n",
    "    FeatureMetadata(\n",
    "        name='month',\n",
    "        display_name='Month',\n",
    "        description='Month component of the timestamp (1-12)',\n",
    "        data_type='int64',\n",
    "        category='temporal',\n",
    "        unit='month',\n",
    "        valid_range=[1, 12],\n",
    "        example_values=[1, 3, 6, 9, 12],\n",
    "        transformation='extract_month_from_timestamp',\n",
    "        source='derived_from_timestamp',\n",
    "        business_meaning='Captures seasonal traffic variations',\n",
    "        importance_score=0.6\n",
    "    ),\n",
    "    FeatureMetadata(\n",
    "        name='hour_sin',\n",
    "        display_name='Hour Sine',\n",
    "        description='Sine transformation of hour for cyclical encoding',\n",
    "        data_type='float64',\n",
    "        category='temporal_cyclical',\n",
    "        unit='dimensionless',\n",
    "        valid_range=[-1, 1],\n",
    "        transformation='sin(2*pi*hour/24)',\n",
    "        source='derived_from_hour',\n",
    "        business_meaning='Captures cyclical nature of daily patterns',\n",
    "        related_features=['hour_cos', 'hour'],\n",
    "        importance_score=0.7\n",
    "    ),\n",
    "    FeatureMetadata(\n",
    "        name='hour_cos',\n",
    "        display_name='Hour Cosine',\n",
    "        description='Cosine transformation of hour for cyclical encoding',\n",
    "        data_type='float64',\n",
    "        category='temporal_cyclical',\n",
    "        unit='dimensionless',\n",
    "        valid_range=[-1, 1],\n",
    "        transformation='cos(2*pi*hour/24)',\n",
    "        source='derived_from_hour',\n",
    "        business_meaning='Captures cyclical nature of daily patterns',\n",
    "        related_features=['hour_sin', 'hour'],\n",
    "        importance_score=0.7\n",
    "    ),\n",
    "    \n",
    "    # Weather Features\n",
    "    FeatureMetadata(\n",
    "        name='temperature',\n",
    "        display_name='Temperature',\n",
    "        description='Air temperature in Celsius',\n",
    "        data_type='float64',\n",
    "        category='weather',\n",
    "        unit='°C',\n",
    "        valid_range=[-30, 50],\n",
    "        example_values=[-5, 0, 10, 20, 30],\n",
    "        source='weather_api',\n",
    "        business_meaning='Temperature affects driving behavior and traffic patterns',\n",
    "        related_features=['is_cold', 'is_hot'],\n",
    "        quality_checks=['range_check', 'outlier_detection'],\n",
    "        importance_score=0.5\n",
    "    ),\n",
    "    FeatureMetadata(\n",
    "        name='precipitation',\n",
    "        display_name='Precipitation',\n",
    "        description='Amount of rainfall in millimeters',\n",
    "        data_type='float64',\n",
    "        category='weather',\n",
    "        unit='mm',\n",
    "        valid_range=[0, 100],\n",
    "        example_values=[0, 1, 5, 10, 20],\n",
    "        source='weather_api',\n",
    "        business_meaning='Rain significantly impacts traffic speed and congestion',\n",
    "        related_features=['is_rainy', 'weather_severity'],\n",
    "        quality_checks=['non_negative', 'outlier_detection'],\n",
    "        importance_score=0.7\n",
    "    ),\n",
    "    FeatureMetadata(\n",
    "        name='visibility',\n",
    "        display_name='Visibility',\n",
    "        description='Visibility distance in meters',\n",
    "        data_type='float64',\n",
    "        category='weather',\n",
    "        unit='m',\n",
    "        valid_range=[0, 15000],\n",
    "        example_values=[100, 500, 1000, 5000, 10000],\n",
    "        source='weather_api',\n",
    "        business_meaning='Low visibility conditions reduce traffic speed for safety',\n",
    "        related_features=['is_foggy', 'weather_severity'],\n",
    "        quality_checks=['non_negative', 'range_check'],\n",
    "        importance_score=0.6\n",
    "    ),\n",
    "    \n",
    "    # Traffic Features\n",
    "    FeatureMetadata(\n",
    "        name='vehicle_count',\n",
    "        display_name='Vehicle Count',\n",
    "        description='Number of vehicles detected in the time period',\n",
    "        data_type='float64',\n",
    "        category='traffic_raw',\n",
    "        unit='vehicles',\n",
    "        valid_range=[0, 500],\n",
    "        example_values=[20, 50, 100, 150, 200],\n",
    "        source='traffic_sensors',\n",
    "        business_meaning='Primary measure of traffic volume',\n",
    "        related_features=['traffic_density', 'flow_efficiency'],\n",
    "        quality_checks=['non_negative', 'reasonable_range'],\n",
    "        importance_score=1.0\n",
    "    ),\n",
    "    FeatureMetadata(\n",
    "        name='avg_speed',\n",
    "        display_name='Average Speed',\n",
    "        description='Average speed of vehicles in km/h',\n",
    "        data_type='float64',\n",
    "        category='traffic_raw',\n",
    "        unit='km/h',\n",
    "        valid_range=[0, 150],\n",
    "        example_values=[30, 50, 80, 100, 120],\n",
    "        source='traffic_sensors',\n",
    "        business_meaning='Indicates traffic flow efficiency and congestion level',\n",
    "        related_features=['traffic_density', 'congestion_score', 'is_congested'],\n",
    "        quality_checks=['non_negative', 'speed_limit_check'],\n",
    "        importance_score=1.0\n",
    "    ),\n",
    "    FeatureMetadata(\n",
    "        name='occupancy',\n",
    "        display_name='Occupancy Rate',\n",
    "        description='Percentage of time the sensor detects vehicles',\n",
    "        data_type='float64',\n",
    "        category='traffic_raw',\n",
    "        unit='%',\n",
    "        valid_range=[0, 100],\n",
    "        example_values=[5, 15, 30, 60, 85],\n",
    "        source='traffic_sensors',\n",
    "        business_meaning='Direct measure of roadway utilization',\n",
    "        related_features=['is_congested', 'congestion_score'],\n",
    "        quality_checks=['percentage_range', 'logical_consistency'],\n",
    "        importance_score=0.9\n",
    "    ),\n",
    "    \n",
    "    # Derived Traffic Features\n",
    "    FeatureMetadata(\n",
    "        name='traffic_density',\n",
    "        display_name='Traffic Density',\n",
    "        description='Vehicle count divided by average speed (density measure)',\n",
    "        data_type='float64',\n",
    "        category='traffic_derived',\n",
    "        unit='vehicles/(km/h)',\n",
    "        transformation='vehicle_count / (avg_speed + 1)',\n",
    "        source='derived_from_vehicle_count_and_avg_speed',\n",
    "        business_meaning='Higher values indicate more congested conditions',\n",
    "        related_features=['vehicle_count', 'avg_speed', 'is_congested'],\n",
    "        importance_score=0.8\n",
    "    ),\n",
    "    FeatureMetadata(\n",
    "        name='flow_efficiency',\n",
    "        display_name='Flow Efficiency',\n",
    "        description='Product of speed and volume (throughput measure)',\n",
    "        data_type='float64',\n",
    "        category='traffic_derived',\n",
    "        unit='(vehicles×km/h)/1000',\n",
    "        transformation='avg_speed * vehicle_count / 1000',\n",
    "        source='derived_from_vehicle_count_and_avg_speed',\n",
    "        business_meaning='Higher values indicate better traffic throughput',\n",
    "        related_features=['vehicle_count', 'avg_speed'],\n",
    "        importance_score=0.7\n",
    "    ),\n",
    "    FeatureMetadata(\n",
    "        name='congestion_score',\n",
    "        display_name='Congestion Score',\n",
    "        description='Composite score indicating congestion level',\n",
    "        data_type='float64',\n",
    "        category='traffic_derived',\n",
    "        unit='score (0-100)',\n",
    "        valid_range=[0, 100],\n",
    "        transformation='clip(occupancy / avg_speed * 100, 0, 100)',\n",
    "        source='derived_from_occupancy_and_avg_speed',\n",
    "        business_meaning='0-30: free flow, 30-60: moderate, 60+: congested',\n",
    "        related_features=['occupancy', 'avg_speed', 'is_congested'],\n",
    "        importance_score=0.8\n",
    "    ),\n",
    "    \n",
    "    # Boolean Features\n",
    "    FeatureMetadata(\n",
    "        name='is_weekend',\n",
    "        display_name='Is Weekend',\n",
    "        description='Binary flag indicating weekend (Saturday/Sunday)',\n",
    "        data_type='int64',\n",
    "        category='temporal_boolean',\n",
    "        valid_range=[0, 1],\n",
    "        example_values=[0, 1],\n",
    "        transformation='1 if day_of_week >= 5 else 0',\n",
    "        source='derived_from_day_of_week',\n",
    "        business_meaning='Weekend traffic patterns differ significantly from weekdays',\n",
    "        related_features=['day_of_week'],\n",
    "        importance_score=0.8\n",
    "    ),\n",
    "    FeatureMetadata(\n",
    "        name='is_rush_hour',\n",
    "        display_name='Is Rush Hour',\n",
    "        description='Binary flag indicating rush hour periods (7-9 AM, 4-6 PM)',\n",
    "        data_type='int64',\n",
    "        category='temporal_boolean',\n",
    "        valid_range=[0, 1],\n",
    "        example_values=[0, 1],\n",
    "        transformation='1 if (7 <= hour < 9) or (16 <= hour < 18) else 0',\n",
    "        source='derived_from_hour',\n",
    "        business_meaning='Rush hours typically show highest traffic volumes',\n",
    "        related_features=['hour', 'is_morning_rush', 'is_evening_rush'],\n",
    "        importance_score=0.9\n",
    "    ),\n",
    "    FeatureMetadata(\n",
    "        name='is_congested',\n",
    "        display_name='Is Congested',\n",
    "        description='Binary flag indicating congested conditions (occupancy > 60%)',\n",
    "        data_type='int64',\n",
    "        category='traffic_boolean',\n",
    "        valid_range=[0, 1],\n",
    "        example_values=[0, 1],\n",
    "        transformation='1 if occupancy / 100 > 0.6 else 0',\n",
    "        source='derived_from_occupancy',\n",
    "        business_meaning='Indicates when traffic conditions are significantly impaired',\n",
    "        related_features=['occupancy', 'congestion_score'],\n",
    "        importance_score=0.8\n",
    "    ),\n",
    "    FeatureMetadata(\n",
    "        name='is_rainy',\n",
    "        display_name='Is Rainy',\n",
    "        description='Binary flag indicating rainy conditions (precipitation > 1mm)',\n",
    "        data_type='int64',\n",
    "        category='weather_boolean',\n",
    "        valid_range=[0, 1],\n",
    "        example_values=[0, 1],\n",
    "        transformation='1 if precipitation > 1.0 else 0',\n",
    "        source='derived_from_precipitation',\n",
    "        business_meaning='Rain conditions significantly impact traffic behavior',\n",
    "        related_features=['precipitation', 'weather_severity'],\n",
    "        importance_score=0.7\n",
    "    ),\n",
    "    \n",
    "    # Station Features\n",
    "    FeatureMetadata(\n",
    "        name='station_id',\n",
    "        display_name='Station ID',\n",
    "        description='Identifier for the traffic measurement station',\n",
    "        data_type='object',\n",
    "        category='station',\n",
    "        example_values=['A1_KM_125', 'A2_KM_89', 'A3_KM_203'],\n",
    "        source='traffic_sensors',\n",
    "        business_meaning='Different stations may have distinct traffic patterns',\n",
    "        related_features=['station_A1KM125', 'station_A2KM89', 'station_A3KM203'],\n",
    "        importance_score=0.6\n",
    "    ),\n",
    "    \n",
    "    # Lag Features\n",
    "    FeatureMetadata(\n",
    "        name='vehicle_count_lag1',\n",
    "        display_name='Vehicle Count (Previous Hour)',\n",
    "        description='Vehicle count from the previous hour (lag-1)',\n",
    "        data_type='float64',\n",
    "        category='temporal_lag',\n",
    "        unit='vehicles',\n",
    "        transformation='lag(vehicle_count, 1)',\n",
    "        source='derived_from_vehicle_count',\n",
    "        business_meaning='Previous traffic conditions influence current state',\n",
    "        related_features=['vehicle_count'],\n",
    "        missing_value_handling='forward_fill_or_drop',\n",
    "        importance_score=0.6\n",
    "    ),\n",
    "    FeatureMetadata(\n",
    "        name='vehicle_count_ma3',\n",
    "        display_name='Vehicle Count (3-Hour Moving Average)',\n",
    "        description='3-hour moving average of vehicle count',\n",
    "        data_type='float64',\n",
    "        category='temporal_smoothed',\n",
    "        unit='vehicles',\n",
    "        transformation='rolling_mean(vehicle_count, window=3)',\n",
    "        source='derived_from_vehicle_count',\n",
    "        business_meaning='Smoothed traffic trend reduces noise in predictions',\n",
    "        related_features=['vehicle_count'],\n",
    "        missing_value_handling='requires_minimum_window',\n",
    "        importance_score=0.5\n",
    "    )\n",
    "]\n",
    "\n",
    "# Add all features to the dictionary\n",
    "for feature in feature_definitions:\n",
    "    feature.created_date = datetime.now().isoformat()\n",
    "    feature.last_updated = datetime.now().isoformat()\n",
    "    data_dict.add_feature(feature)\n",
    "\n",
    "print(f'Added {len(feature_definitions)} feature definitions to data dictionary')\n",
    "print(f'Categories: {list(data_dict.categories.keys())}')\n",
    "print(f'Total features in dictionary: {len(data_dict.features)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Data Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T13:40:47.905968Z",
     "iopub.status.busy": "2025-09-06T13:40:47.905889Z",
     "iopub.status.idle": "2025-09-06T13:40:47.963130Z",
     "shell.execute_reply": "2025-09-06T13:40:47.962867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Report Generated:\n",
      "========================================\n",
      "Total Records: 2,000\n",
      "Total Features: 44\n",
      "Memory Usage: 0.75 MB\n",
      "Duplicates: 0\n",
      "\n",
      "Missing Values Summary:\n",
      "  vehicle_count_lag1: 0.1%\n",
      "  avg_speed_lag1: 0.1%\n",
      "  occupancy_lag1: 0.1%\n",
      "  vehicle_count_ma3: 0.1%\n",
      "  avg_speed_ma3: 0.1%\n",
      "\n",
      "Outliers Summary:\n",
      "  avg_speed: 0.7%\n",
      "  occupancy: 0.9%\n",
      "  temperature: 0.8%\n",
      "  precipitation: 4.0%\n",
      "  wind_speed: 4.7%\n",
      "  humidity: 0.3%\n",
      "  is_holiday: 4.5%\n",
      "  is_morning_rush: 8.3%\n",
      "  is_evening_rush: 8.3%\n",
      "  is_rush_hour: 16.6%\n",
      "\n",
      "Validation Results:\n",
      "  hour: {'exists': True, 'type_match': False, 'range_valid': True, 'out_of_range_count': 0}\n",
      "  day_of_week: {'exists': True, 'type_match': False, 'range_valid': True, 'out_of_range_count': 0}\n",
      "  month: {'exists': True, 'type_match': False, 'range_valid': True, 'out_of_range_count': 0}\n"
     ]
    }
   ],
   "source": [
    "def generate_data_quality_report(df: pd.DataFrame, data_dict: DataDictionary) -> Dict[str, Any]:\n",
    "    \"\"\"Generate comprehensive data quality report.\"\"\"\n",
    "    \n",
    "    quality_report = {\n",
    "        'dataset_overview': {\n",
    "            'total_records': len(df),\n",
    "            'total_features': len(df.columns),\n",
    "            'memory_usage_mb': df.memory_usage(deep=True).sum() / 1024 / 1024,\n",
    "            'date_range': {\n",
    "                'start': df['timestamp'].min().isoformat() if 'timestamp' in df.columns else None,\n",
    "                'end': df['timestamp'].max().isoformat() if 'timestamp' in df.columns else None\n",
    "            }\n",
    "        },\n",
    "        'data_quality': {\n",
    "            'missing_values': {},\n",
    "            'data_types': {},\n",
    "            'value_ranges': {},\n",
    "            'outliers': {},\n",
    "            'duplicates': df.duplicated().sum()\n",
    "        },\n",
    "        'feature_statistics': {},\n",
    "        'validation_results': {}\n",
    "    }\n",
    "    \n",
    "    # Missing values analysis\n",
    "    for col in df.columns:\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        missing_pct = (missing_count / len(df)) * 100\n",
    "        quality_report['data_quality']['missing_values'][col] = {\n",
    "            'count': missing_count,\n",
    "            'percentage': round(missing_pct, 2)\n",
    "        }\n",
    "    \n",
    "    # Data types\n",
    "    for col in df.columns:\n",
    "        quality_report['data_quality']['data_types'][col] = str(df[col].dtype)\n",
    "    \n",
    "    # Value ranges for numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        quality_report['data_quality']['value_ranges'][col] = {\n",
    "            'min': float(df[col].min()),\n",
    "            'max': float(df[col].max()),\n",
    "            'mean': float(df[col].mean()),\n",
    "            'std': float(df[col].std())\n",
    "        }\n",
    "    \n",
    "    # Outlier detection (IQR method)\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = df[(df[col] < Q1 - 1.5 * IQR) | (df[col] > Q3 + 1.5 * IQR)]\n",
    "        quality_report['data_quality']['outliers'][col] = {\n",
    "            'count': len(outliers),\n",
    "            'percentage': round((len(outliers) / len(df)) * 100, 2)\n",
    "        }\n",
    "    \n",
    "    # Feature statistics\n",
    "    for col in df.columns:\n",
    "        if col in numeric_cols:\n",
    "            stats = df[col].describe()\n",
    "            quality_report['feature_statistics'][col] = {\n",
    "                'count': int(stats['count']),\n",
    "                'mean': float(stats['mean']),\n",
    "                'std': float(stats['std']),\n",
    "                'min': float(stats['min']),\n",
    "                '25%': float(stats['25%']),\n",
    "                '50%': float(stats['50%']),\n",
    "                '75%': float(stats['75%']),\n",
    "                'max': float(stats['max']),\n",
    "                'unique_values': int(df[col].nunique()),\n",
    "                'zero_values': int((df[col] == 0).sum())\n",
    "            }\n",
    "        else:\n",
    "            quality_report['feature_statistics'][col] = {\n",
    "                'count': int(df[col].count()),\n",
    "                'unique_values': int(df[col].nunique()),\n",
    "                'top_value': str(df[col].mode().iloc[0]) if not df[col].mode().empty else None,\n",
    "                'most_common_frequency': int(df[col].value_counts().iloc[0]) if len(df[col].value_counts()) > 0 else 0\n",
    "            }\n",
    "    \n",
    "    # Validation against data dictionary\n",
    "    for feature_name, feature_meta in data_dict.features.items():\n",
    "        if feature_name in df.columns:\n",
    "            validation_results = {\n",
    "                'exists': True,\n",
    "                'type_match': str(df[feature_name].dtype) == feature_meta.data_type,\n",
    "                'range_valid': True\n",
    "            }\n",
    "            \n",
    "            # Check valid range\n",
    "            if feature_meta.valid_range and feature_name in numeric_cols:\n",
    "                min_val, max_val = feature_meta.valid_range\n",
    "                out_of_range = ((df[feature_name] < min_val) | (df[feature_name] > max_val)).sum()\n",
    "                validation_results['range_valid'] = out_of_range == 0\n",
    "                validation_results['out_of_range_count'] = int(out_of_range)\n",
    "            \n",
    "            quality_report['validation_results'][feature_name] = validation_results\n",
    "        else:\n",
    "            quality_report['validation_results'][feature_name] = {\n",
    "                'exists': False,\n",
    "                'type_match': False,\n",
    "                'range_valid': False\n",
    "            }\n",
    "    \n",
    "    return quality_report\n",
    "\n",
    "# Generate quality report\n",
    "quality_report = generate_data_quality_report(sample_data, data_dict)\n",
    "\n",
    "print('Data Quality Report Generated:')\n",
    "print('=' * 40)\n",
    "print(f'Total Records: {quality_report[\"dataset_overview\"][\"total_records\"]:,}')\n",
    "print(f'Total Features: {quality_report[\"dataset_overview\"][\"total_features\"]}')\n",
    "print(f'Memory Usage: {quality_report[\"dataset_overview\"][\"memory_usage_mb\"]:.2f} MB')\n",
    "print(f'Duplicates: {quality_report[\"data_quality\"][\"duplicates\"]}')\n",
    "\n",
    "print('\\nMissing Values Summary:')\n",
    "missing_summary = [(k, v['percentage']) for k, v in quality_report['data_quality']['missing_values'].items() if v['percentage'] > 0]\n",
    "if missing_summary:\n",
    "    for feature, pct in missing_summary[:10]:  # Top 10\n",
    "        print(f'  {feature}: {pct:.1f}%')\n",
    "else:\n",
    "    print('  No missing values detected')\n",
    "\n",
    "print('\\nOutliers Summary:')\n",
    "outlier_summary = [(k, v['percentage']) for k, v in quality_report['data_quality']['outliers'].items() if v['percentage'] > 0]\n",
    "for feature, pct in outlier_summary[:10]:  # Top 10\n",
    "    print(f'  {feature}: {pct:.1f}%')\n",
    "\n",
    "print('\\nValidation Results:')\n",
    "validation_issues = [(k, v) for k, v in quality_report['validation_results'].items() if not all([v.get('exists', False), v.get('type_match', False), v.get('range_valid', False)])]\n",
    "if validation_issues:\n",
    "    for feature, issues in validation_issues[:5]:\n",
    "        print(f'  {feature}: {issues}')\n",
    "else:\n",
    "    print('  All validations passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Markdown Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T13:40:47.964334Z",
     "iopub.status.busy": "2025-09-06T13:40:47.964207Z",
     "iopub.status.idle": "2025-09-06T13:40:47.979317Z",
     "shell.execute_reply": "2025-09-06T13:40:47.979140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown documentation saved to: /home/niko/workspace/slovenia-traffic/notebooks/docs/traffic_data_dictionary.md\n",
      "Documentation size: 19,871 characters\n",
      "\n",
      "Documentation Preview:\n",
      "==================================================\n",
      "# Traffic Data Dictionary\n",
      "**Generated on:** 2025-09-06 15:40:47\n",
      "**Total Features:** 22\n",
      "**Categories:** 11\n",
      "\n",
      "## Table of Contents\n",
      "- [Dataset Overview](#dataset-overview)\n",
      "- [Data Quality Summary](#data-quality-summary)\n",
      "- [Feature Categories](#feature-categories)\n",
      "  - [Station](#station)\n",
      "  - [Temporal](#temporal)\n",
      "  - [Temporal Boolean](#temporal-boolean)\n",
      "  - [Temporal Cyclical](#temporal-cyclical)\n",
      "  - [Temporal Lag](#temporal-lag)\n",
      "  - [Temporal Smoothed](#temporal-smoothed)\n",
      "  - [Traffic Boolean](#traffic-boolean)\n",
      "  - [Traffic Derived](#traffic-derived)\n",
      "  - [Traffic Raw](#traffic-raw)\n",
      "  - [Weather](#weather)\n",
      "  - [Weather Boolean](#weather-boolean)\n",
      "- [Feature Relationships](#feature-relationships)\n",
      "- [Data Transformations](#data-transformations)\n",
      "\n",
      "## Dataset Overview\n",
      "\n",
      "- **Total Records:** 2,000\n",
      "- **Total Features:** 44\n",
      "- **Memory Usage:** 0.75 MB\n",
      "- **Date Range:** 2024-01-01T00:00:00 to 2024-03-24T07:00:00\n",
      "\n",
      "## Data Quality Summary\n",
      "\n",
      "- **Duplicate Records:** 0\n",
      "- **Features with Missing Values:** ...\n"
     ]
    }
   ],
   "source": [
    "def generate_markdown_documentation(data_dict: DataDictionary, quality_report: Dict[str, Any]) -> str:\n",
    "    \"\"\"Generate comprehensive markdown documentation.\"\"\"\n",
    "    \n",
    "    md_content = []\n",
    "    md_content.append('# Traffic Data Dictionary\\n')\n",
    "    md_content.append(f'**Generated on:** {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\\n')\n",
    "    md_content.append(f'**Total Features:** {len(data_dict.features)}\\n')\n",
    "    md_content.append(f'**Categories:** {len(data_dict.categories)}\\n\\n')\n",
    "    \n",
    "    # Table of Contents\n",
    "    md_content.append('## Table of Contents\\n')\n",
    "    md_content.append('- [Dataset Overview](#dataset-overview)\\n')\n",
    "    md_content.append('- [Data Quality Summary](#data-quality-summary)\\n')\n",
    "    md_content.append('- [Feature Categories](#feature-categories)\\n')\n",
    "    \n",
    "    for category in sorted(data_dict.categories.keys()):\n",
    "        category_title = category.replace('_', ' ').title()\n",
    "        md_content.append(f'  - [{category_title}](#{category.replace(\"_\", \"-\")})\\n')\n",
    "    \n",
    "    md_content.append('- [Feature Relationships](#feature-relationships)\\n')\n",
    "    md_content.append('- [Data Transformations](#data-transformations)\\n\\n')\n",
    "    \n",
    "    # Dataset Overview\n",
    "    md_content.append('## Dataset Overview\\n\\n')\n",
    "    overview = quality_report['dataset_overview']\n",
    "    md_content.append(f'- **Total Records:** {overview[\"total_records\"]:,}\\n')\n",
    "    md_content.append(f'- **Total Features:** {overview[\"total_features\"]}\\n')\n",
    "    md_content.append(f'- **Memory Usage:** {overview[\"memory_usage_mb\"]:.2f} MB\\n')\n",
    "    if overview['date_range']['start']:\n",
    "        md_content.append(f'- **Date Range:** {overview[\"date_range\"][\"start\"]} to {overview[\"date_range\"][\"end\"]}\\n')\n",
    "    md_content.append('\\n')\n",
    "    \n",
    "    # Data Quality Summary\n",
    "    md_content.append('## Data Quality Summary\\n\\n')\n",
    "    quality = quality_report['data_quality']\n",
    "    md_content.append(f'- **Duplicate Records:** {quality[\"duplicates\"]}\\n')\n",
    "    \n",
    "    missing_features = [k for k, v in quality['missing_values'].items() if v['percentage'] > 0]\n",
    "    md_content.append(f'- **Features with Missing Values:** {len(missing_features)}\\n')\n",
    "    \n",
    "    outlier_features = [k for k, v in quality['outliers'].items() if v['percentage'] > 5]\n",
    "    md_content.append(f'- **Features with >5% Outliers:** {len(outlier_features)}\\n\\n')\n",
    "    \n",
    "    # Feature Categories\n",
    "    md_content.append('## Feature Categories\\n\\n')\n",
    "    \n",
    "    for category, feature_names in sorted(data_dict.categories.items()):\n",
    "        category_title = category.replace('_', ' ').title()\n",
    "        md_content.append(f'### {category_title}\\n\\n')\n",
    "        md_content.append(f'**Count:** {len(feature_names)} features\\n\\n')\n",
    "        \n",
    "        # Create table for features in this category\n",
    "        md_content.append('| Feature | Display Name | Type | Unit | Description |\\n')\n",
    "        md_content.append('|---------|--------------|------|------|-------------|\\n')\n",
    "        \n",
    "        for feature_name in sorted(feature_names):\n",
    "            if feature_name in data_dict.features:\n",
    "                feature = data_dict.features[feature_name]\n",
    "                unit = feature.unit or 'N/A'\n",
    "                desc = feature.description[:80] + '...' if len(feature.description) > 80 else feature.description\n",
    "                md_content.append(f'| `{feature.name}` | {feature.display_name} | {feature.data_type} | {unit} | {desc} |\\n')\n",
    "        \n",
    "        md_content.append('\\n')\n",
    "    \n",
    "    # Detailed Feature Descriptions\n",
    "    md_content.append('## Detailed Feature Descriptions\\n\\n')\n",
    "    \n",
    "    for category, feature_names in sorted(data_dict.categories.items()):\n",
    "        category_title = category.replace('_', ' ').title()\n",
    "        md_content.append(f'### {category_title} Features\\n\\n')\n",
    "        \n",
    "        for feature_name in sorted(feature_names):\n",
    "            if feature_name in data_dict.features:\n",
    "                feature = data_dict.features[feature_name]\n",
    "                \n",
    "                md_content.append(f'#### `{feature.name}`\\n\\n')\n",
    "                md_content.append(f'**Display Name:** {feature.display_name}\\n\\n')\n",
    "                md_content.append(f'**Description:** {feature.description}\\n\\n')\n",
    "                md_content.append(f'**Data Type:** `{feature.data_type}`\\n\\n')\n",
    "                \n",
    "                if feature.unit:\n",
    "                    md_content.append(f'**Unit:** {feature.unit}\\n\\n')\n",
    "                \n",
    "                if feature.valid_range:\n",
    "                    md_content.append(f'**Valid Range:** {feature.valid_range[0]} to {feature.valid_range[1]}\\n\\n')\n",
    "                \n",
    "                if feature.example_values:\n",
    "                    md_content.append(f'**Example Values:** {feature.example_values}\\n\\n')\n",
    "                \n",
    "                if feature.transformation:\n",
    "                    md_content.append(f'**Transformation:** `{feature.transformation}`\\n\\n')\n",
    "                \n",
    "                if feature.source:\n",
    "                    md_content.append(f'**Source:** {feature.source}\\n\\n')\n",
    "                \n",
    "                if feature.business_meaning:\n",
    "                    md_content.append(f'**Business Meaning:** {feature.business_meaning}\\n\\n')\n",
    "                \n",
    "                if feature.related_features:\n",
    "                    related = ', '.join([f'`{rf}`' for rf in feature.related_features])\n",
    "                    md_content.append(f'**Related Features:** {related}\\n\\n')\n",
    "                \n",
    "                if feature.quality_checks:\n",
    "                    checks = ', '.join(feature.quality_checks)\n",
    "                    md_content.append(f'**Quality Checks:** {checks}\\n\\n')\n",
    "                \n",
    "                if feature.importance_score is not None:\n",
    "                    md_content.append(f'**Importance Score:** {feature.importance_score:.1f}/1.0\\n\\n')\n",
    "                \n",
    "                if feature.missing_value_handling:\n",
    "                    md_content.append(f'**Missing Value Handling:** {feature.missing_value_handling}\\n\\n')\n",
    "                \n",
    "                md_content.append('---\\n\\n')\n",
    "    \n",
    "    # Feature Relationships\n",
    "    md_content.append('## Feature Relationships\\n\\n')\n",
    "    md_content.append('### Derivation Chain\\n\\n')\n",
    "    \n",
    "    relationships = {}\n",
    "    for feature_name, feature in data_dict.features.items():\n",
    "        if feature.related_features:\n",
    "            relationships[feature_name] = feature.related_features\n",
    "    \n",
    "    if relationships:\n",
    "        md_content.append('| Feature | Related Features |\\n')\n",
    "        md_content.append('|---------|------------------|\\n')\n",
    "        for feature, related in sorted(relationships.items()):\n",
    "            related_list = ', '.join([f'`{rf}`' for rf in related])\n",
    "            md_content.append(f'| `{feature}` | {related_list} |\\n')\n",
    "    \n",
    "    md_content.append('\\n')\n",
    "    \n",
    "    # Data Transformations\n",
    "    md_content.append('## Data Transformations\\n\\n')\n",
    "    \n",
    "    transformations = {}\n",
    "    for feature_name, feature in data_dict.features.items():\n",
    "        if feature.transformation:\n",
    "            transformations[feature_name] = {\n",
    "                'formula': feature.transformation,\n",
    "                'source': feature.source\n",
    "            }\n",
    "    \n",
    "    if transformations:\n",
    "        md_content.append('| Feature | Transformation Formula | Source |\\n')\n",
    "        md_content.append('|---------|------------------------|--------|\\n')\n",
    "        for feature, transform_info in sorted(transformations.items()):\n",
    "            formula = transform_info['formula']\n",
    "            source = transform_info['source'] or 'N/A'\n",
    "            md_content.append(f'| `{feature}` | `{formula}` | {source} |\\n')\n",
    "    \n",
    "    md_content.append('\\n')\n",
    "    \n",
    "    # Quality Issues\n",
    "    md_content.append('## Data Quality Issues\\n\\n')\n",
    "    \n",
    "    # Missing values\n",
    "    missing_issues = [(k, v) for k, v in quality_report['data_quality']['missing_values'].items() if v['percentage'] > 0]\n",
    "    if missing_issues:\n",
    "        md_content.append('### Missing Values\\n\\n')\n",
    "        md_content.append('| Feature | Missing Count | Missing % |\\n')\n",
    "        md_content.append('|---------|---------------|-----------|\\n')\n",
    "        for feature, missing_info in sorted(missing_issues, key=lambda x: x[1]['percentage'], reverse=True):\n",
    "            md_content.append(f'| `{feature}` | {missing_info[\"count\"]} | {missing_info[\"percentage\"]}% |\\n')\n",
    "        md_content.append('\\n')\n",
    "    \n",
    "    # Outliers\n",
    "    outlier_issues = [(k, v) for k, v in quality_report['data_quality']['outliers'].items() if v['percentage'] > 1]\n",
    "    if outlier_issues:\n",
    "        md_content.append('### Outliers (>1%)\\n\\n')\n",
    "        md_content.append('| Feature | Outlier Count | Outlier % |\\n')\n",
    "        md_content.append('|---------|---------------|-----------|\\n')\n",
    "        for feature, outlier_info in sorted(outlier_issues, key=lambda x: x[1]['percentage'], reverse=True):\n",
    "            md_content.append(f'| `{feature}` | {outlier_info[\"count\"]} | {outlier_info[\"percentage\"]}% |\\n')\n",
    "        md_content.append('\\n')\n",
    "    \n",
    "    # Usage Guidelines\n",
    "    md_content.append('## Usage Guidelines\\n\\n')\n",
    "    md_content.append('### Best Practices\\n\\n')\n",
    "    md_content.append('1. **Temporal Features**: Use cyclical encoding (sin/cos) for hour, day, and month features to capture periodic patterns.\\n')\n",
    "    md_content.append('2. **Weather Impact**: Combine weather boolean flags for comprehensive weather condition assessment.\\n')\n",
    "    md_content.append('3. **Traffic Metrics**: Use derived metrics (density, flow_efficiency) for better model performance.\\n')\n",
    "    md_content.append('4. **Missing Values**: Handle lag and rolling features appropriately - they naturally have missing values at the beginning.\\n')\n",
    "    md_content.append('5. **Outliers**: Review outliers in traffic metrics as they may indicate incidents or sensor malfunctions.\\n\\n')\n",
    "    \n",
    "    md_content.append('### Feature Selection Recommendations\\n\\n')\n",
    "    high_importance = [f for f in data_dict.features.values() if f.importance_score and f.importance_score >= 0.8]\n",
    "    high_importance.sort(key=lambda x: x.importance_score, reverse=True)\n",
    "    \n",
    "    md_content.append('**High Importance Features (Score ≥ 0.8):**\\n\\n')\n",
    "    for feature in high_importance:\n",
    "        md_content.append(f'- `{feature.name}` ({feature.importance_score:.1f}): {feature.business_meaning}\\n')\n",
    "    \n",
    "    md_content.append('\\n---\\n\\n')\n",
    "    md_content.append(f'*Documentation generated automatically on {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}*\\n')\n",
    "    \n",
    "    return ''.join(md_content)\n",
    "\n",
    "# Generate markdown documentation\n",
    "markdown_doc = generate_markdown_documentation(data_dict, quality_report)\n",
    "\n",
    "# Save markdown documentation\n",
    "docs_dir = Path('docs')\n",
    "docs_dir.mkdir(exist_ok=True)\n",
    "markdown_file = docs_dir / 'traffic_data_dictionary.md'\n",
    "\n",
    "with open(markdown_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(markdown_doc)\n",
    "\n",
    "print(f'Markdown documentation saved to: {markdown_file.absolute()}')\n",
    "print(f'Documentation size: {len(markdown_doc):,} characters')\n",
    "\n",
    "# Show preview\n",
    "print('\\nDocumentation Preview:')\n",
    "print('=' * 50)\n",
    "print(markdown_doc[:1000] + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Data Dictionary and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T13:40:47.980424Z",
     "iopub.status.busy": "2025-09-06T13:40:47.980313Z",
     "iopub.status.idle": "2025-09-06T13:40:47.995522Z",
     "shell.execute_reply": "2025-09-06T13:40:47.995354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Dictionary Export Complete:\n",
      "========================================\n",
      "Output directory: /home/niko/workspace/slovenia-traffic/notebooks/data_dictionary_outputs\n",
      "\n",
      "Files created:\n",
      "✓ traffic_data_dictionary.json - JSON data dictionary\n",
      "✓ traffic_data_dictionary.yaml - YAML data dictionary\n",
      "✓ data_quality_report.json - Data quality report\n",
      "✓ feature_summary.csv - Feature summary CSV\n",
      "✓ comprehensive_metadata.json - Comprehensive metadata\n",
      "✓ traffic_data_dictionary.md - Markdown documentation\n",
      "\n",
      "File sizes:\n",
      "  traffic_data_dictionary.json: 18.7 KB\n",
      "  traffic_data_dictionary.yaml: 15.0 KB\n",
      "  data_quality_report.json: 29.2 KB\n",
      "  feature_summary.csv: 2.1 KB\n",
      "  comprehensive_metadata.json: 55.0 KB\n",
      "  traffic_data_dictionary.md: 19.4 KB\n",
      "\n",
      "Feature breakdown by category:\n",
      "  Station: 1 features\n",
      "  Temporal: 4 features\n",
      "  Temporal Boolean: 2 features\n",
      "  Temporal Cyclical: 2 features\n",
      "  Temporal Lag: 1 features\n",
      "  Temporal Smoothed: 1 features\n",
      "  Traffic Boolean: 1 features\n",
      "  Traffic Derived: 3 features\n",
      "  Traffic Raw: 3 features\n",
      "  Weather: 3 features\n",
      "  Weather Boolean: 1 features\n",
      "\n",
      "Total documented features: 22\n"
     ]
    }
   ],
   "source": [
    "# Save data dictionary in multiple formats\n",
    "output_dir = Path('data_dictionary_outputs')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# JSON format\n",
    "json_file = output_dir / 'traffic_data_dictionary.json'\n",
    "data_dict.save_json(json_file)\n",
    "\n",
    "# YAML format\n",
    "yaml_file = output_dir / 'traffic_data_dictionary.yaml'\n",
    "data_dict.save_yaml(yaml_file)\n",
    "\n",
    "# Quality report\n",
    "quality_file = output_dir / 'data_quality_report.json'\n",
    "with open(quality_file, 'w') as f:\n",
    "    json.dump(quality_report, f, indent=2, default=str)\n",
    "\n",
    "# Feature summary CSV\n",
    "feature_summary = []\n",
    "for feature_name, feature in data_dict.features.items():\n",
    "    summary_row = {\n",
    "        'feature_name': feature.name,\n",
    "        'display_name': feature.display_name,\n",
    "        'category': feature.category,\n",
    "        'data_type': feature.data_type,\n",
    "        'unit': feature.unit,\n",
    "        'source': feature.source,\n",
    "        'importance_score': feature.importance_score,\n",
    "        'has_transformation': bool(feature.transformation),\n",
    "        'has_business_meaning': bool(feature.business_meaning),\n",
    "        'quality_checks_count': len(feature.quality_checks) if feature.quality_checks else 0\n",
    "    }\n",
    "    feature_summary.append(summary_row)\n",
    "\n",
    "summary_df = pd.DataFrame(feature_summary)\n",
    "summary_file = output_dir / 'feature_summary.csv'\n",
    "summary_df.to_csv(summary_file, index=False)\n",
    "\n",
    "# Create comprehensive metadata file\n",
    "comprehensive_metadata = {\n",
    "    'metadata_info': {\n",
    "        'generated_at': datetime.now().isoformat(),\n",
    "        'generator': 'Traffic Data Dictionary Notebook',\n",
    "        'version': '1.0.0'\n",
    "    },\n",
    "    'dataset_info': quality_report['dataset_overview'],\n",
    "    'data_dictionary': data_dict.to_dict(),\n",
    "    'data_quality': quality_report,\n",
    "    'feature_categories': {\n",
    "        category: {\n",
    "            'count': len(features),\n",
    "            'features': features,\n",
    "            'description': f'Features related to {category.replace(\"_\", \" \")}'\n",
    "        }\n",
    "        for category, features in data_dict.categories.items()\n",
    "    },\n",
    "    'usage_guidelines': {\n",
    "        'high_importance_features': [\n",
    "            f.name for f in data_dict.features.values() \n",
    "            if f.importance_score and f.importance_score >= 0.8\n",
    "        ],\n",
    "        'derived_features': [\n",
    "            f.name for f in data_dict.features.values() \n",
    "            if f.transformation\n",
    "        ],\n",
    "        'required_preprocessing': [\n",
    "            'Handle missing values in lag and rolling features',\n",
    "            'Validate data ranges against feature definitions',\n",
    "            'Apply cyclical encoding for temporal features',\n",
    "            'Check for outliers in traffic metrics'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "comprehensive_file = output_dir / 'comprehensive_metadata.json'\n",
    "with open(comprehensive_file, 'w') as f:\n",
    "    json.dump(comprehensive_metadata, f, indent=2, default=str)\n",
    "\n",
    "print('Data Dictionary Export Complete:')\n",
    "print('=' * 40)\n",
    "print(f'Output directory: {output_dir.absolute()}')\n",
    "print('\\nFiles created:')\n",
    "print(f'✓ {json_file.name} - JSON data dictionary')\n",
    "print(f'✓ {yaml_file.name} - YAML data dictionary')\n",
    "print(f'✓ {quality_file.name} - Data quality report')\n",
    "print(f'✓ {summary_file.name} - Feature summary CSV')\n",
    "print(f'✓ {comprehensive_file.name} - Comprehensive metadata')\n",
    "print(f'✓ {markdown_file.name} - Markdown documentation')\n",
    "\n",
    "# File size summary\n",
    "print('\\nFile sizes:')\n",
    "for file_path in [json_file, yaml_file, quality_file, summary_file, comprehensive_file, markdown_file]:\n",
    "    size_kb = file_path.stat().st_size / 1024\n",
    "    print(f'  {file_path.name}: {size_kb:.1f} KB')\n",
    "\n",
    "print('\\nFeature breakdown by category:')\n",
    "for category, features in sorted(data_dict.categories.items()):\n",
    "    print(f'  {category.replace(\"_\", \" \").title()}: {len(features)} features')\n",
    "\n",
    "print(f'\\nTotal documented features: {len(data_dict.features)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Interactive Feature Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T13:40:47.996626Z",
     "iopub.status.busy": "2025-09-06T13:40:47.996544Z",
     "iopub.status.idle": "2025-09-06T13:40:48.001210Z",
     "shell.execute_reply": "2025-09-06T13:40:48.001045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive feature explorer saved to: /home/niko/workspace/slovenia-traffic/notebooks/docs/feature_explorer.html\n",
      "HTML file size: 63,949 characters\n",
      "\n",
      "Open the HTML file in a web browser to explore features interactively!\n"
     ]
    }
   ],
   "source": [
    "def create_feature_explorer_html(data_dict: DataDictionary, quality_report: Dict[str, Any]) -> str:\n",
    "    \"\"\"Create interactive HTML feature explorer.\"\"\"\n",
    "    \n",
    "    html_content = f'''\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Traffic Data Dictionary - Feature Explorer</title>\n",
    "    <style>\n",
    "        body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; margin: 0; padding: 20px; background: #f5f5f5; }}\n",
    "        .container {{ max-width: 1200px; margin: 0 auto; background: white; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}\n",
    "        .header {{ background: #2c3e50; color: white; padding: 20px; border-radius: 8px 8px 0 0; }}\n",
    "        .header h1 {{ margin: 0; font-size: 2em; }}\n",
    "        .header p {{ margin: 10px 0 0 0; opacity: 0.8; }}\n",
    "        .controls {{ padding: 20px; border-bottom: 1px solid #eee; background: #f8f9fa; }}\n",
    "        .search-box {{ width: 100%; padding: 10px; border: 1px solid #ddd; border-radius: 4px; font-size: 16px; margin-bottom: 10px; }}\n",
    "        .filters {{ display: flex; gap: 10px; flex-wrap: wrap; }}\n",
    "        .filter {{ padding: 8px 12px; background: #007bff; color: white; border: none; border-radius: 20px; cursor: pointer; font-size: 12px; }}\n",
    "        .filter.active {{ background: #28a745; }}\n",
    "        .stats {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; padding: 20px; }}\n",
    "        .stat-card {{ background: #f8f9fa; padding: 15px; border-radius: 8px; text-align: center; }}\n",
    "        .stat-number {{ font-size: 2em; font-weight: bold; color: #2c3e50; }}\n",
    "        .stat-label {{ color: #666; margin-top: 5px; }}\n",
    "        .features {{ padding: 20px; }}\n",
    "        .feature-card {{ border: 1px solid #e1e8ed; border-radius: 8px; margin-bottom: 15px; background: white; overflow: hidden; }}\n",
    "        .feature-header {{ background: #f8f9fa; padding: 15px; border-bottom: 1px solid #e1e8ed; cursor: pointer; }}\n",
    "        .feature-name {{ font-weight: bold; color: #2c3e50; font-size: 16px; }}\n",
    "        .feature-type {{ color: #666; font-size: 12px; background: #e9ecef; padding: 2px 6px; border-radius: 3px; margin-left: 10px; }}\n",
    "        .category-badge {{ color: white; font-size: 11px; padding: 2px 8px; border-radius: 12px; margin-left: 10px; }}\n",
    "        .feature-details {{ padding: 15px; display: none; }}\n",
    "        .feature-details.show {{ display: block; }}\n",
    "        .detail-row {{ display: grid; grid-template-columns: 120px 1fr; gap: 10px; margin-bottom: 8px; }}\n",
    "        .detail-label {{ font-weight: bold; color: #666; }}\n",
    "        .detail-value {{ color: #333; }}\n",
    "        .importance-bar {{ height: 6px; background: #e9ecef; border-radius: 3px; overflow: hidden; }}\n",
    "        .importance-fill {{ height: 100%; background: linear-gradient(90deg, #28a745, #ffc107, #dc3545); }}\n",
    "        .hidden {{ display: none !important; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <div class=\"header\">\n",
    "            <h1>Traffic Data Dictionary</h1>\n",
    "            <p>Interactive Feature Explorer - Generated {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}</p>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"stats\">\n",
    "            <div class=\"stat-card\">\n",
    "                <div class=\"stat-number\">{len(data_dict.features)}</div>\n",
    "                <div class=\"stat-label\">Total Features</div>\n",
    "            </div>\n",
    "            <div class=\"stat-card\">\n",
    "                <div class=\"stat-number\">{len(data_dict.categories)}</div>\n",
    "                <div class=\"stat-label\">Categories</div>\n",
    "            </div>\n",
    "            <div class=\"stat-card\">\n",
    "                <div class=\"stat-number\">{quality_report[\"dataset_overview\"][\"total_records\"]:,}</div>\n",
    "                <div class=\"stat-label\">Data Records</div>\n",
    "            </div>\n",
    "            <div class=\"stat-card\">\n",
    "                <div class=\"stat-number\">{quality_report[\"dataset_overview\"][\"memory_usage_mb\"]:.1f} MB</div>\n",
    "                <div class=\"stat-label\">Memory Usage</div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"controls\">\n",
    "            <input type=\"text\" class=\"search-box\" placeholder=\"Search features...\" id=\"searchBox\">\n",
    "            <div class=\"filters\" id=\"categoryFilters\">\n",
    "                <button class=\"filter active\" data-category=\"all\">All Features</button>\n",
    "'''\n",
    "    \n",
    "    # Add category filters\n",
    "    category_colors = {\n",
    "        'temporal': '#007bff',\n",
    "        'weather': '#28a745',\n",
    "        'traffic': '#dc3545',\n",
    "        'station': '#6f42c1',\n",
    "        'derived': '#fd7e14',\n",
    "        'boolean': '#20c997'\n",
    "    }\n",
    "    \n",
    "    for category in sorted(data_dict.categories.keys()):\n",
    "        category_title = category.replace('_', ' ').title()\n",
    "        color = category_colors.get(category.split('_')[0], '#6c757d')\n",
    "        count = len(data_dict.categories[category])\n",
    "        html_content += f'<button class=\"filter\" data-category=\"{category}\" style=\"background-color: {color};\">{category_title} ({count})</button>\\n'\n",
    "    \n",
    "    html_content += '''\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"features\" id=\"featuresContainer\">\n",
    "'''\n",
    "    \n",
    "    # Add feature cards\n",
    "    for feature_name, feature in sorted(data_dict.features.items()):\n",
    "        category_color = category_colors.get(feature.category.split('_')[0], '#6c757d')\n",
    "        importance_width = (feature.importance_score * 100) if feature.importance_score else 0\n",
    "        \n",
    "        html_content += f'''\n",
    "            <div class=\"feature-card\" data-category=\"{feature.category}\" data-name=\"{feature.name.lower()}\">\n",
    "                <div class=\"feature-header\" onclick=\"toggleFeature('{feature.name}')\">\n",
    "                    <span class=\"feature-name\">{feature.name}</span>\n",
    "                    <span class=\"feature-type\">{feature.data_type}</span>\n",
    "                    <span class=\"category-badge\" style=\"background-color: {category_color};\">{feature.category.replace('_', ' ')}</span>\n",
    "                </div>\n",
    "                <div class=\"feature-details\" id=\"details_{feature.name}\">\n",
    "                    <div class=\"detail-row\">\n",
    "                        <span class=\"detail-label\">Display Name:</span>\n",
    "                        <span class=\"detail-value\">{feature.display_name}</span>\n",
    "                    </div>\n",
    "                    <div class=\"detail-row\">\n",
    "                        <span class=\"detail-label\">Description:</span>\n",
    "                        <span class=\"detail-value\">{feature.description}</span>\n",
    "                    </div>\n",
    "'''\n",
    "        \n",
    "        if feature.unit:\n",
    "            html_content += f'''\n",
    "                    <div class=\"detail-row\">\n",
    "                        <span class=\"detail-label\">Unit:</span>\n",
    "                        <span class=\"detail-value\">{feature.unit}</span>\n",
    "                    </div>\n",
    "'''\n",
    "        \n",
    "        if feature.valid_range:\n",
    "            html_content += f'''\n",
    "                    <div class=\"detail-row\">\n",
    "                        <span class=\"detail-label\">Valid Range:</span>\n",
    "                        <span class=\"detail-value\">{feature.valid_range[0]} to {feature.valid_range[1]}</span>\n",
    "                    </div>\n",
    "'''\n",
    "        \n",
    "        if feature.transformation:\n",
    "            html_content += f'''\n",
    "                    <div class=\"detail-row\">\n",
    "                        <span class=\"detail-label\">Transformation:</span>\n",
    "                        <span class=\"detail-value\"><code>{feature.transformation}</code></span>\n",
    "                    </div>\n",
    "'''\n",
    "        \n",
    "        if feature.source:\n",
    "            html_content += f'''\n",
    "                    <div class=\"detail-row\">\n",
    "                        <span class=\"detail-label\">Source:</span>\n",
    "                        <span class=\"detail-value\">{feature.source}</span>\n",
    "                    </div>\n",
    "'''\n",
    "        \n",
    "        if feature.business_meaning:\n",
    "            html_content += f'''\n",
    "                    <div class=\"detail-row\">\n",
    "                        <span class=\"detail-label\">Business Meaning:</span>\n",
    "                        <span class=\"detail-value\">{feature.business_meaning}</span>\n",
    "                    </div>\n",
    "'''\n",
    "        \n",
    "        if feature.importance_score is not None:\n",
    "            html_content += f'''\n",
    "                    <div class=\"detail-row\">\n",
    "                        <span class=\"detail-label\">Importance:</span>\n",
    "                        <span class=\"detail-value\">\n",
    "                            {feature.importance_score:.1f}/1.0\n",
    "                            <div class=\"importance-bar\">\n",
    "                                <div class=\"importance-fill\" style=\"width: {importance_width}%;\"></div>\n",
    "                            </div>\n",
    "                        </span>\n",
    "                    </div>\n",
    "'''\n",
    "        \n",
    "        if feature.related_features:\n",
    "            related = ', '.join(feature.related_features)\n",
    "            html_content += f'''\n",
    "                    <div class=\"detail-row\">\n",
    "                        <span class=\"detail-label\">Related:</span>\n",
    "                        <span class=\"detail-value\">{related}</span>\n",
    "                    </div>\n",
    "'''\n",
    "        \n",
    "        html_content += '''\n",
    "                </div>\n",
    "            </div>\n",
    "'''\n",
    "    \n",
    "    html_content += '''\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <script>\n",
    "        function toggleFeature(featureName) {\n",
    "            const details = document.getElementById('details_' + featureName);\n",
    "            details.classList.toggle('show');\n",
    "        }\n",
    "        \n",
    "        function filterFeatures() {\n",
    "            const searchTerm = document.getElementById('searchBox').value.toLowerCase();\n",
    "            const activeCategory = document.querySelector('.filter.active').getAttribute('data-category');\n",
    "            const featureCards = document.querySelectorAll('.feature-card');\n",
    "            \n",
    "            featureCards.forEach(card => {\n",
    "                const featureName = card.getAttribute('data-name');\n",
    "                const featureCategory = card.getAttribute('data-category');\n",
    "                \n",
    "                const matchesSearch = featureName.includes(searchTerm);\n",
    "                const matchesCategory = activeCategory === 'all' || featureCategory === activeCategory;\n",
    "                \n",
    "                if (matchesSearch && matchesCategory) {\n",
    "                    card.classList.remove('hidden');\n",
    "                } else {\n",
    "                    card.classList.add('hidden');\n",
    "                }\n",
    "            });\n",
    "        }\n",
    "        \n",
    "        document.getElementById('searchBox').addEventListener('input', filterFeatures);\n",
    "        \n",
    "        document.querySelectorAll('.filter').forEach(filter => {\n",
    "            filter.addEventListener('click', function() {\n",
    "                document.querySelectorAll('.filter').forEach(f => f.classList.remove('active'));\n",
    "                this.classList.add('active');\n",
    "                filterFeatures();\n",
    "            });\n",
    "        });\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "    \n",
    "    return html_content\n",
    "\n",
    "# Generate interactive HTML explorer\n",
    "html_explorer = create_feature_explorer_html(data_dict, quality_report)\n",
    "\n",
    "# Save HTML explorer\n",
    "html_file = docs_dir / 'feature_explorer.html'\n",
    "with open(html_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(html_explorer)\n",
    "\n",
    "print(f'Interactive feature explorer saved to: {html_file.absolute()}')\n",
    "print(f'HTML file size: {len(html_explorer):,} characters')\n",
    "print('\\nOpen the HTML file in a web browser to explore features interactively!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Usage Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T13:40:48.002239Z",
     "iopub.status.busy": "2025-09-06T13:40:48.002158Z",
     "iopub.status.idle": "2025-09-06T13:40:48.005681Z",
     "shell.execute_reply": "2025-09-06T13:40:48.005519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA DICTIONARY COMPLETE\n",
      "============================================================\n",
      "\n",
      "Accomplishments:\n",
      "✓ Created comprehensive data dictionary structure\n",
      "✓ Documented all traffic, weather, and temporal features\n",
      "✓ Generated detailed feature metadata\n",
      "✓ Built data quality assessment\n",
      "✓ Created markdown documentation\n",
      "✓ Exported multiple formats (JSON, YAML, CSV)\n",
      "✓ Built interactive HTML feature explorer\n",
      "✓ Analyzed feature relationships and transformations\n",
      "✓ Provided usage guidelines and best practices\n",
      "\n",
      "Data Dictionary Contents:\n",
      "• Total Features Documented: 22\n",
      "• Feature Categories: 11\n",
      "• Category Breakdown:\n",
      "  - Station: 1 features\n",
      "  - Temporal: 4 features\n",
      "  - Temporal Boolean: 2 features\n",
      "  - Temporal Cyclical: 2 features\n",
      "  - Temporal Lag: 1 features\n",
      "  - Temporal Smoothed: 1 features\n",
      "  - Traffic Boolean: 1 features\n",
      "  - Traffic Derived: 3 features\n",
      "  - Traffic Raw: 3 features\n",
      "  - Weather: 3 features\n",
      "  - Weather Boolean: 1 features\n",
      "\n",
      "Generated Files:\n",
      "• docs/traffic_data_dictionary.md - Comprehensive documentation\n",
      "• docs/feature_explorer.html - Interactive feature explorer\n",
      "• data_dictionary_outputs/traffic_data_dictionary.json - JSON format\n",
      "• data_dictionary_outputs/traffic_data_dictionary.yaml - YAML format\n",
      "• data_dictionary_outputs/feature_summary.csv - Feature summary\n",
      "• data_dictionary_outputs/data_quality_report.json - Quality report\n",
      "• data_dictionary_outputs/comprehensive_metadata.json - Complete metadata\n",
      "\n",
      "Feature Highlights:\n",
      "• High Importance Features:\n",
      "  - timestamp (1.0): When the traffic measurement was taken...\n",
      "  - vehicle_count (1.0): Primary measure of traffic volume...\n",
      "  - avg_speed (1.0): Indicates traffic flow efficiency and congestion l...\n",
      "  - hour (0.9): Used to identify daily traffic patterns and peak h...\n",
      "  - occupancy (0.9): Direct measure of roadway utilization...\n",
      "  - is_rush_hour (0.9): Rush hours typically show highest traffic volumes...\n",
      "  - day_of_week (0.8): Distinguishes weekday vs weekend traffic patterns...\n",
      "  - traffic_density (0.8): Higher values indicate more congested conditions...\n",
      "  - congestion_score (0.8): 0-30: free flow, 30-60: moderate, 60+: congested...\n",
      "  - is_weekend (0.8): Weekend traffic patterns differ significantly from...\n",
      "• Derived Features: 14 (with transformations)\n",
      "\n",
      "Usage Instructions:\n",
      "1. **For Developers**: Use JSON/YAML files for programmatic access\n",
      "2. **For Data Scientists**: Review markdown documentation for feature understanding\n",
      "3. **For Analysts**: Use interactive HTML explorer to browse features\n",
      "4. **For Documentation**: Reference comprehensive metadata for reports\n",
      "5. **For Quality Assurance**: Check data quality report for issues\n",
      "\n",
      "Best Practices:\n",
      "• Always validate data against feature definitions\n",
      "• Use importance scores for feature selection\n",
      "• Apply recommended transformations for derived features\n",
      "• Handle missing values according to feature specifications\n",
      "• Monitor data quality metrics regularly\n",
      "\n",
      "Integration with Other Notebooks:\n",
      "• Pipeline Automation (24): Use metadata for validation\n",
      "• Feature Engineering (16): Reference transformations\n",
      "• Data Quality (19): Compare against quality thresholds\n",
      "• Feature Store (22): Use for feature versioning\n",
      "\n",
      "Next Steps:\n",
      "• Deploy data dictionary to production systems\n",
      "• Integrate with data pipelines for validation\n",
      "• Set up automated quality monitoring\n",
      "• Create feature lineage tracking\n",
      "• Establish data governance workflows\n"
     ]
    }
   ],
   "source": [
    "print('=' * 60)\n",
    "print('DATA DICTIONARY COMPLETE')\n",
    "print('=' * 60)\n",
    "print('\\nAccomplishments:')\n",
    "print('✓ Created comprehensive data dictionary structure')\n",
    "print('✓ Documented all traffic, weather, and temporal features')\n",
    "print('✓ Generated detailed feature metadata')\n",
    "print('✓ Built data quality assessment')\n",
    "print('✓ Created markdown documentation')\n",
    "print('✓ Exported multiple formats (JSON, YAML, CSV)')\n",
    "print('✓ Built interactive HTML feature explorer')\n",
    "print('✓ Analyzed feature relationships and transformations')\n",
    "print('✓ Provided usage guidelines and best practices')\n",
    "\n",
    "print('\\nData Dictionary Contents:')\n",
    "print(f'• Total Features Documented: {len(data_dict.features)}')\n",
    "print(f'• Feature Categories: {len(data_dict.categories)}')\n",
    "print('• Category Breakdown:')\n",
    "for category, features in sorted(data_dict.categories.items()):\n",
    "    print(f'  - {category.replace(\"_\", \" \").title()}: {len(features)} features')\n",
    "\n",
    "print('\\nGenerated Files:')\n",
    "print(f'• docs/traffic_data_dictionary.md - Comprehensive documentation')\n",
    "print(f'• docs/feature_explorer.html - Interactive feature explorer')\n",
    "print(f'• data_dictionary_outputs/traffic_data_dictionary.json - JSON format')\n",
    "print(f'• data_dictionary_outputs/traffic_data_dictionary.yaml - YAML format')\n",
    "print(f'• data_dictionary_outputs/feature_summary.csv - Feature summary')\n",
    "print(f'• data_dictionary_outputs/data_quality_report.json - Quality report')\n",
    "print(f'• data_dictionary_outputs/comprehensive_metadata.json - Complete metadata')\n",
    "\n",
    "print('\\nFeature Highlights:')\n",
    "high_importance = [f for f in data_dict.features.values() if f.importance_score and f.importance_score >= 0.8]\n",
    "high_importance.sort(key=lambda x: x.importance_score, reverse=True)\n",
    "print('• High Importance Features:')\n",
    "for feature in high_importance[:10]:  # Top 10\n",
    "    print(f'  - {feature.name} ({feature.importance_score:.1f}): {feature.business_meaning[:50]}...')\n",
    "\n",
    "derived_features = [f for f in data_dict.features.values() if f.transformation]\n",
    "print(f'• Derived Features: {len(derived_features)} (with transformations)')\n",
    "\n",
    "print('\\nUsage Instructions:')\n",
    "print('1. **For Developers**: Use JSON/YAML files for programmatic access')\n",
    "print('2. **For Data Scientists**: Review markdown documentation for feature understanding')\n",
    "print('3. **For Analysts**: Use interactive HTML explorer to browse features')\n",
    "print('4. **For Documentation**: Reference comprehensive metadata for reports')\n",
    "print('5. **For Quality Assurance**: Check data quality report for issues')\n",
    "\n",
    "print('\\nBest Practices:')\n",
    "print('• Always validate data against feature definitions')\n",
    "print('• Use importance scores for feature selection')\n",
    "print('• Apply recommended transformations for derived features')\n",
    "print('• Handle missing values according to feature specifications')\n",
    "print('• Monitor data quality metrics regularly')\n",
    "\n",
    "print('\\nIntegration with Other Notebooks:')\n",
    "print('• Pipeline Automation (24): Use metadata for validation')\n",
    "print('• Feature Engineering (16): Reference transformations')\n",
    "print('• Data Quality (19): Compare against quality thresholds')\n",
    "print('• Feature Store (22): Use for feature versioning')\n",
    "\n",
    "print('\\nNext Steps:')\n",
    "print('• Deploy data dictionary to production systems')\n",
    "print('• Integrate with data pipelines for validation')\n",
    "print('• Set up automated quality monitoring')\n",
    "print('• Create feature lineage tracking')\n",
    "print('• Establish data governance workflows')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
